{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment on the impact of data sampling on training and testing time and accuracy\n",
    "\n",
    "\n",
    "More data is not always beneficial as may be suggested in most cases. This is particularly so when a few data point captures most of predictive signals presents the full dataset hence there is some amount of redundancy in the dataset. In most cases, redudant data comes at a cost higher than benefit offered to improving model accuracy. \n",
    "\n",
    "\n",
    "More data means longer training time and higher computation cost but not necessarily higher marginal accuracy hence there is the need to seek a sweet spot where an acceptable level of accuracy is achieved with the least training time and computation cost possible.\n",
    "\n",
    "A common approach to reduce training time is to reduce the training dataset using intelligent sampling techniques that capture the bulk of the features present in the full dataset. Verifying the usefulness of the sampling technique in achieving that is one that is empirical involving training of the full dataset as well for comparison. But this process once done, decides the sampling technique hence the time save for using that technique to reduce data for training in the long run is rather tremendous.\n",
    "\n",
    "\n",
    "This work seeks to demonstrates the benefit of using representative sampling of dataset in the computer vision space. The objective are to:\n",
    "\n",
    "1. To test the proposition that representative sampling offers minimal opportunity cost for model accuracy in the face of high computational cost reduction compared to training with full dataset\n",
    "2. To identify the representative sampling technique that offers the most optimal benefit of least reduction of model accuracy and higher reduction in training time\n",
    "3. To quantify the benefits of using the various representative sampling technique in the form of percentage reduction in training time vs accuraacy compared full dataset training\n",
    "   \n",
    "\n",
    "### Methodology\n",
    "\n",
    "To understand the impact of various representative sampling techniques, the full data was used for training and the training time and various evaluation metrics recorded for the test set.\n",
    "\n",
    "cluster random representative sampling, Centroid representative sampling results and Near duplicate removal sampling was used on the train and validation dataset to reduce then by 50% in each case.\n",
    "The results were then used for training and tested on the same test dataset \n",
    "as used when training on full data\n",
    "\n",
    "#### Training task\n",
    "Instance segmentation\n",
    "\n",
    "#### Model used\n",
    "Maskrcnnresnet50\n",
    "\n",
    "#### Number of epochs set\n",
    "20\n",
    "\n",
    "#### Framework used\n",
    "Openvino Trianing extension (otx) for training and datumaro for dataset pruning (representative sampling)\n",
    "\n",
    "#### Dataset used\n",
    "cocoa ripeness \n",
    "\n",
    "#### Representative sampling techniques used\n",
    "cluster random representative sampling, Centroid representative sampling results and Near duplicate removal samplin\n",
    "\n",
    "\n",
    "\n",
    "NB: No data cleaning or filtering was undertaken in all cases\n",
    "\n",
    "ALL DATA TRAINING RESULT\n",
    "\n",
    "Epoch 16/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 603/603 0:04:21 • 0:00:00 2.23it/s v_num: 0 train/loss_rpn_cls: 0.002               \n",
    "                                                                                        train/loss_rpn_bbox: 0.002 train/loss_cls: 0.011 \n",
    "                                                                                        train/loss_bbox: 0.025 train/loss_mask: 0.040    \n",
    "                                                                                        train/loss: 0.079 validation/data_time: 0.005    \n",
    "                                                                                        validation/iter_time: 0.087 val/map: 0.720       \n",
    "                                                                                        val/map_50: 0.778 val/map_75: 0.771              \n",
    "                                                                                        val/map_small: 0.198 val/map_medium: 0.565       \n",
    "                                                                                        val/map_large: 0.775 val/mar_1: 0.641 val/mar_10:\n",
    "                                                                                        0.910 val/mar_100: 0.910 val/mar_small: 0.549    \n",
    "                                                                                        val/mar_medium: 0.882 val/mar_large: 0.960       \n",
    "                                                                                        val/map_per_class: -1.000 val/mar_100_per_class: \n",
    "                                                                                        -1.000 val/f1-score: 0.683 train/data_time: 0.013\n",
    "                                                                                        train/iter_time: 0.433                           \n",
    "Elapsed time: 1:40:05.112484\n",
    "\n",
    "Testing results \n",
    "\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃        Test metric        ┃       DataLoader 0        ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│      test/data_time       │   0.0038684236351400614   │\n",
    "│       test/f1-score       │    0.7150904536247253     │\n",
    "│      test/iter_time       │   0.058442387729883194    │\n",
    "│         test/map          │    0.7164003849029541     │\n",
    "│        test/map_50        │    0.7748006582260132     │\n",
    "│        test/map_75        │    0.7619205117225647     │\n",
    "│      test/map_large       │    0.7924619317054749     │\n",
    "│      test/map_medium      │    0.5712788701057434     │\n",
    "│    test/map_per_class     │           -1.0            │\n",
    "│      test/map_small       │    0.3468170464038849     │\n",
    "│        test/mar_1         │    0.6534634232521057     │\n",
    "│        test/mar_10        │    0.9099258780479431     │\n",
    "│       test/mar_100        │     0.912447452545166     │\n",
    "│  test/mar_100_per_class   │           -1.0            │\n",
    "│      test/mar_large       │     0.961567223072052     │\n",
    "│      test/mar_medium      │    0.8701627850532532     │\n",
    "│      test/mar_small       │    0.6988954544067383     │\n",
    "└───────────────────────────┴───────────────────────────┘\n",
    "Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 822/822 0:00:53 • 0:00:00 17.49it/s  \n",
    "Elapsed time: 0:01:22.079637\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of experiment\n",
    "-visualize number of train and val samples for each method\n",
    "- visualize the train and test time for each method\n",
    "- visualize evalize metrics as comparison \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
